{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************************\n",
    "#  The Social Web \n",
    "- Instructors Davide Ceolin, Dayana Spagnuelo\n",
    "- Exercises for Hands-on session 1\n",
    "- 6 February 2020 11:00 - 12:45                 \n",
    "- NU-5B-21, NU-6A-04, NU-6B-20, NU-6C-39, NU-6C-40                             \n",
    "*****************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites:\n",
    "- Python 3.7\n",
    "- Python packages: twitter, prettytable, matplotlib\n",
    "\n",
    "First you need to know how to retrieve some social web data. Exercises 1 and 2 will show you how to retrieve trends and search results from Twitter. \n",
    "\n",
    "But let's check first if we're running a sufficiently new version of Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "print(\"This jupyter notebook is running on Python \" + platform.python_version())\n",
    "# It's good practice to assert packages requirements at the beginning of a script:\n",
    "assert sys.version_info >= (3, 6) # Tested with Python==3.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install now the required packages for this hands on session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're using a virtualenv, make sure its activated before running \n",
    "# this cell!\n",
    "!pip install twitter PrettyTable matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Authorizing an application to access Twitter account data (from Example 1-1/9-1 in Mining the Social Web):\n",
    "\n",
    "1. Make sure to add your mobile phone number to your private twitter profile.\n",
    "2. Go to https://apps.twitter.com/ and click on \"create an app\". Twitter will prompt you to create a *developer account*.\n",
    "3. You'll receive an *account confirmation* email with a link. Follow it and create an app. \n",
    "4. Once the app is created, you'll see a \"Keys and Token\" item on the top left-hand side corner of the webpage. This values will be needed to fill in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter # Tell Python to use the twitter package\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "# to get the oauth credential you need to click on the 'Generate access token' button:\n",
    "OAUTH_TOKEN = '' \n",
    "OAUTH_TOKEN_SECRET = ''\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "print(twitter_api) \n",
    "# Nothing to see by displaying twitter_api except that it's now a defined variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Retrieving twitter search trends (from Example 1-2/9-2 in Mining the Social Web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORLD_WOE_ID = 1 # The \"Yahoo! Where On Earth ID\" for the entire world\n",
    "world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID) # get back a callable\n",
    "print(world_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Find out how WORLD_WOE_IDs are defined by Yahoo and try to use others in a query. What kind of differences do you find between the worldwide trends and the local trends? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Retrieving search results (from Example 1-5/9-3 in Mining the Social Web):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '#ThrowbackThursday' # XXX: Set this variable to a trending topic, or anything else you like. \n",
    "count = 100 # number of results to retrieve\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets for more info\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count) # search for your query 'q' 100 times\n",
    "statuses = search_results['statuses'] # extract the tweets found\n",
    "\n",
    "# The following code allows you to print in a nice format the contents of search_results\n",
    "import json\n",
    "print(type(statuses))\n",
    "print(json.dumps(statuses[0], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "In the cell below, create a second variable (e.g. `statuses2`) that holds the results of a query other than the one presented above. Think about a query that would yield very different results than the first one, for example one that may yield a shorter output or about a different topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extracting text, screen names, and hashtags from tweets (from Example 1-6 in Mining the Social Web)\n",
    "\n",
    "Simply printing all the search results to screen is nice, but to really start analysing them, it is handy to select the interesting parts and store them in a different structure such as a list. \n",
    "\n",
    "In this example you are using a thing called \"List Comprehension\".\n",
    "\n",
    "### 2.1 List Comprehensions\n",
    "List comprehension is a powerful construct that allows to succinctly build a list.\n",
    "With it you can process items from any iterable (e.g. dictionaries, lists, tuples, iterators...) and output a list while optionally performing an operation on each value.\n",
    "\n",
    "Here's a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double all values from 0 to 9\n",
    "double_list = [i*2 for i in range(10)]\n",
    "# raise to the power of 2, but only if the number is uneven\n",
    "power_even_list = [i**2 for i in range(10) if i%2!=0]\n",
    "# clean strings in a tuple\n",
    "stripped_lines = [x.strip() for x in ('The\\n', 'Social\\n', 'Web\\n')]\n",
    "# return length of each string in stripped_lines\n",
    "len_str_lines = [len(s) for s in stripped_lines]\n",
    "# finally, we can nest list comprehensions to flatten a list of lists:\n",
    "list_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "range_9 = [x for y in list_of_lists for x in y]\n",
    "\n",
    "print(double_list)\n",
    "print(power_even_list)\n",
    "print(stripped_lines)\n",
    "print(len_str_lines)\n",
    "print(range_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Parsing text, screen names and hashtags from tweets\n",
    "*(from Example 1-6 in Mining the Social Web)*\n",
    "\n",
    "Hereafter, we'll be creating a variable `status_texts` of type list. \\\n",
    "The list will be filled with the `text` elements from each `status`, whereas `status` comes from looping through all `statuses` in the `search_results` list (1.2). \\\n",
    "Look up the list comprehensions in your Python reference materials to make sure you understand what's happening here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_texts = [ status['text'] for status in statuses ]\n",
    "# the escape character \"\\\" allows for the list comprehension to continue\n",
    "# on a new line. While not strictly necessary, it makes code more readable\n",
    "# for your fellow programmers.\n",
    "screen_names = [ user_mention['screen_name'] for status in statuses \\\n",
    "                for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "hashtags = [ hashtag['text'] for status in statuses \\\n",
    "        for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [ w for t in status_texts for w in t.split() ] #split the string on the empty spaces\n",
    "\n",
    "# Explore the first 5 items for each...\n",
    "print(json.dumps(status_texts[0:5], indent=1))\n",
    "print(json.dumps(screen_names[0:5], indent=1))\n",
    "print(json.dumps(hashtags[0:5], indent=1))\n",
    "print(json.dumps(words[0:5], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "You are now ready to parse usernames, hashtags and text from the results you previously obtained in Task 2 (e.g. `statuses_2`). While doing it, make sure to leave the variables created in 2.2 untouched. Instead, create your own variable names, which you'll be using soon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Creating a basic frequency distribution from words in tweets\n",
    "*(from Examples 1-7 in Mining the Social Web)* \n",
    "\n",
    "\n",
    "In the cell below we display the 10 most common hashtag instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    \n",
    "print(c.most_common()[:10]) # top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like this: \\\n",
    "`[('ThrowbackThursday', 34), ('throwbackthursday', 11), ('TBT', 6), ('ThrowBackThursday', 6), ('Trivia', 3), ('madoka_magica', 2), ('New', 2), ('EURO2020', 2), ('artists', 2)]`\n",
    "\n",
    "### Task 4\n",
    "Show hashtags frequency for results that you obtained in Task 3. Think about possible explanations for the different results you get from the analyses for the different queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Storing your results\n",
    "So far, we have been storing the data in working memory. Often it's handy to store your data to disk so you can retrieve it in a next session. \n",
    "\n",
    "The pickle module lets you do exactly that, by serializing data in a binary format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filepath = \"my_data.pickle\"\n",
    "# this indented python syntax is broadly defined as \"context manager\".\n",
    "# This means that everything happening under its indentation will use f\n",
    "# as file handle to filepath. The Shortand `wb` stands for \"write binary\",\n",
    "# which is how we serialize data to disk.\n",
    "with open(filepath, \"wb\") as f:\n",
    "    pickle.dump(words, f) # write the contents of list 'words' to file 'f'\n",
    "    \n",
    "# Note that, after the end of the indented block, the file is automatically closed.\n",
    "# Hence, no memory resource on your system is wasted idly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you browse to your working directory, you should find a file there named \"myData.pickle\". You can open this in a text editor, or load its contents back into a variable to do some more analyses on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the myData.pickle file and store its contents into variable 'words'\n",
    "\n",
    "with open(filepath, \"rb\") as f:\n",
    "    words = pickle.load(f)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Using prettytable to display tuples in a nice way\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "for label, data in (('Word', words),\n",
    "                    ('Screen Name', screen_names),\n",
    "                    ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count'])\n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Calculating lexical diversity for tweets \n",
    "*(from Example 1-9 in Mining the Social Web)*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for computing lexical diversity\n",
    "def lexical_diversity(tokens):\n",
    "    return 1.0*len(set(tokens))/len(tokens)\n",
    "\n",
    "# Define a function for computing the average number of words per tweet\n",
    "def average_words(statuses):\n",
    "    total_words = sum([ len(s.split()) for s in statuses ])\n",
    "    return 1.0*total_words/len(statuses) \n",
    "\n",
    "# Let's use these functions:\n",
    "\n",
    "print(lexical_diversity(words))\n",
    "print(lexical_diversity(screen_names))\n",
    "print(lexical_diversity(hashtags))\n",
    "print(average_words(status_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: What do the printed numbers indicate? Try to explain them.\n",
    "\n",
    "(*Double click this cell to write your answer*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Finding the most popular retweets \n",
    "*(from Example 1-10 in Mining the Social Web):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_cnt_un_txt = [(status['retweet_count'],\n",
    "    status['retweeted_status']['user']['screen_name'],\n",
    "    status['text'])# Store out a tuple of these three values\n",
    "    for status in statuses # for each status\n",
    "    if 'retweeted_status' in status # ... so long as the status meets this condition.\n",
    "    ]\n",
    "\n",
    "# Slice off the first 5 from the sorted results and display each item in the tuple\n",
    "pt = PrettyTable(field_names=['Count', 'Screen Name', 'Text'])\n",
    "[ pt.add_row(row) for row in sorted(retweet_cnt_un_txt, reverse=True)[:5] ]\n",
    "pt.max_width['Text'] = 50\n",
    "pt.align= 'l'\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Looking up users who have retweeted a status \n",
    "*(from Example 1-11 in Mining the Social Web):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_retweets = twitter_api.statuses.retweets(id=1224140327688249349) # Get the original tweet id for a tweet from its retweeted_status node and insert it here\n",
    "print(\"Users who've retweeted the tweet:\\n\")\n",
    "print([r['user']['screen_name'] for r in _retweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (advanced)\n",
    "\n",
    "If you have a Twitter account with a nontrivial number of tweets, request your historical tweet archive from your account settings and analyze it. \\\n",
    "The export of your account data includes files organized by time period in a convenient JSON format. See the README.txt file included in the downloaded archive for more details. \n",
    "\n",
    "\n",
    "\n",
    "What are the most common terms that appear in your tweets? \\\n",
    "Who do you retweet the most often? \\\n",
    "How many of your tweets are retweeted (and why do you think this is the case)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Plotting frequencies of words \n",
    "*(from Example 1-12 in Mining the Social Web)*\n",
    "\n",
    "\n",
    "In the previous exercises we have been looking at the text from the tweets, but when you retrieved the results, you retrieved much more information about the tweets, such as the username of the person who shared this tweet with the world. \n",
    "\n",
    "\n",
    "You can use this information to find out who retweets whom in our examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = sorted(Counter(words).values(), reverse=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.loglog(word_counts)\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.xlabel(\"Word Rank\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating histograms of words, screen names, and hashtags \n",
    "*(from Example 1-13 in Mining the Social Web):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [count for count, _, _ in retweets]\n",
    "plt.hist(counts)\n",
    "plt.title(\"Retweets\")\n",
    "plt.xlabel('Bins (number of times retweeted)')\n",
    "plt.ylabel('Number of tweets in bin')\n",
    "print(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra: seaborn plots with a one-liner.\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(counts, kde=False, rug=True);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
